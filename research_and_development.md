
# Ã‰thique et Intelligence Artificielle 

## Quâ€™est-ce que lâ€™Ã©thique de lâ€™IA ?

Lâ€™Ã©thique est un ensemble de principes moraux qui nous aident Ã  distinguer le bien du mal. Lâ€™Ã©thique de lâ€™IA est un domaine pluridisciplinaire qui Ã©tudie comment optimiser lâ€™impact bÃ©nÃ©fique de lâ€™intelligence artificielle (IA) tout en rÃ©duisant ses risques et ses effets indÃ©sirables.

## Les principes de lâ€™Ã©thique IA

**Respect des personnes :** ce principe reconnaÃ®t lâ€™autonomie des individus et permet aux chercheurs de protÃ©ger les personnes dont lâ€™autonomie est rÃ©duite, ce qui peut Ãªtre dÃ» Ã  diverses circonstances telles que la maladie, un handicap mental, des restrictions dâ€™Ã¢ge. Ce principe touche principalement lâ€™idÃ©e de consentement. Les personnes doivent Ãªtre conscientes des risques et des avantages potentiels de toute expÃ©rience Ã  laquelle elles participent, et elles doivent pouvoir choisir de participer ou de sâ€™en retirer Ã  tout moment avant et pendant lâ€™expÃ©rience.

**Bienveillance :** ce principe sort du cadre de lâ€™Ã©thique des soins de santÃ©, oÃ¹ les mÃ©decins prÃªtent serment de Â« ne pas nuire Â». Cette idÃ©e peut Ãªtre facilement appliquÃ©e Ã  lâ€™intelligence artificielle, oÃ¹ les algorithmes peuvent amplifier les prÃ©jugÃ©s liÃ©s Ã  la race, au genre, aux opinions politiques, etc., malgrÃ© lâ€™intention de faire le bien et dâ€™amÃ©liorer un systÃ¨me donnÃ©.

**Justice :** ce principe traite de questions telles que lâ€™Ã©quitÃ© et lâ€™Ã©galitÃ©. Qui doit profiter des avantages de lâ€™expÃ©rimentation et du machine learning ? Le rapport Belmont propose cinq faÃ§ons de rÃ©partir les charges et les avantages :
  - Partage Ã©quitable
  - Besoin individuel
  - Effort individuel
  - Contribution sociÃ©tale
  - MÃ©rite

[Source](https://www.ibm.com/fr-fr/think/topics/ai-ethics)

## âœ… Bonnes pratiques Ã©thiques

- **Respecter les droits fondamentaux et la vie privÃ©e**  
  Ne collectez que les donnÃ©es nÃ©cessaires, informez clairement les utilisateurs et obtenez leur consentement.
  [Source](https://www.lumenova.ai/blog/perspectives-on-ai-governance-dos-and-donts)

- **Assurer lâ€™Ã©quitÃ© et Ã©viter les biais**  
  VÃ©rifiez que les donnÃ©es dâ€™entraÃ®nement sont diversifiÃ©es. Mettez en place des mÃ©canismes pour dÃ©tecter et corriger les discriminations.
    [Source](https://www.pmi.org/blog/top-10-ethical-considerations-for-ai-projects)

- **Garantir la transparence et lâ€™explicabilitÃ©**  
  Expliquez aux utilisateurs comment lâ€™IA arrive Ã  ses dÃ©cisions. IntÃ©grer des outils dâ€™Â«â€¯Explainable AIâ€¯Â» pour surmonter lâ€™effet de boÃ®te noire.
      [Source](https://www.pmi.org/blog/top-10-ethical-considerations-for-ai-projects)

- **Maintenir lâ€™humain dans la boucle**  
  PrivilÃ©giez le jugement humain, surtout pour les dÃ©cisions Ã  forts enjeux (santÃ©, justice, emploiâ€¦).
  [Source](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)
  

- **Assurer sÃ©curitÃ©, robustesse et durabilitÃ©**  
  ProtÃ©gez les systÃ¨mes contre les attaques et minimisez leur impact environnemental.

- **Ã‰tablir responsabilitÃ© et gouvernance**  
  Documentez et auditez les systÃ¨mes dâ€™IA, dÃ©finissez qui est responsable en cas de problÃ¨me.
    [Source](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)

- **Favoriser la collaboration et consultation**  
  Impliquez parties prenantes, experts et utilisateurs dÃ¨s la conception, adoptez une approche multidisciplinaire.
  [Source](https://en.wikipedia.org/wiki/Joy_Buolamwini)
  

- **Concevoir centrÃ© sur les valeurs humaines**  
  Utilisez des mÃ©thodes comme le *Value Sensitive Design* pour intÃ©grer les valeurs morales dÃ¨s le dÃ©part.
    [Source](https://en.wikipedia.org/wiki/Value_sensitive_design)

## ğŸš« Ã€ Ã©viter (Donâ€™ts)

- **Ne pas se reposer aveuglÃ©ment sur lâ€™IA**  
  Lâ€™automatisation complÃ¨te sans supervision humaine peut conduire Ã  des erreurs graves.
  [Source](https://www.instituteofaistudies.com/insights/ai-ethics-the-dos-and-donts-of-ai)

- **Ne pas ignorer les biais des donnÃ©es**  
  Se passer de contrÃ´le ou dâ€™audit introduit des biais non dÃ©tectÃ©s.

- **Ne pas violer la vie privÃ©e**  
  Ã‰vitez les collectes excessives sans raison ni consentement.

- **Ne pas sacrifier la sÃ©curitÃ©**  
  Compromettre la sÃ©curitÃ© pour lâ€™innovation expose Ã  des risques Ã©thiques et lÃ©gaux.

- **Ne pas se contenter dâ€™une gouvernance Ã  cocher**  
  Un cadre rigide ou trop bureaucratique empÃªche lâ€™innovation et ne sâ€™adapte pas.

- **Ne pas donner trop de pouvoir Ã  lâ€™IA**  
  Ne laissez jamais lâ€™IA prendre des dÃ©cisions affectant directement les droits ou la vie des personnes.

- **Ne pas nÃ©gliger lâ€™impact environnemental**  
  Les modÃ¨les IA gourmands en Ã©nergie doivent Ãªtre optimisÃ©s ou compensÃ©s.
    [Source](https://unsceb.org/sites/default/files/2022-09/Principles%20for%20the%20Ethical%20Use%20of%20AI%20in%20the%20UN%20System_1.pdf)

## ğŸ¨ En design (UX, design crÃ©atifâ€¦)

- **DÃ©clarer lâ€™usage de lâ€™IA**  
  Soyez transparent, mentionnez quand un visuel ou un texte est gÃ©nÃ©rÃ©.

- **Ne pas remplacer la recherche utilisateur**  
  Lâ€™IA ne doit pas se substituer aux mÃ©thodes qualitatives (entretiens, observations).

- **PrivilÃ©gier une IA comme assistant**  
  Lâ€™IA gÃ©nÃ¨re des propositions, le designer les critique, les filtre et les enrichit.

- **Cultiver la diversitÃ© et lâ€™inclusion**  
  IntÃ©grez des perspectives plurielles pour Ã©viter biais et stÃ©rÃ©otypes visuels.


## ğŸ“š Pour aller plus loin

- **UNESCO** : recommandations centrÃ©es sur les droits humains  
- **Toptal** : Ã©quitÃ©, transparence et responsabilitÃ© en design  
- **IA ACT** : [La loi europÃ©enne sur l'intelligence artificielle](https://artificialintelligenceact.eu/fr/)