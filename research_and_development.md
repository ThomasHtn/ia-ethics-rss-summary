
# Ã‰thique et Intelligence Artificielle : Bonnes et Mauvaises Pratiques

## âœ… Bonnes pratiques Ã©thiques

- **Respecter les droits fondamentaux et la vie privÃ©e**  
  Ne collectez que les donnÃ©es nÃ©cessaires, informez clairement les utilisateurs et obtenez leur consentement.
  [Source](https://www.lumenova.ai/blog/perspectives-on-ai-governance-dos-and-donts)

- **Assurer lâ€™Ã©quitÃ© et Ã©viter les biais**  
  VÃ©rifiez que les donnÃ©es dâ€™entraÃ®nement sont diversifiÃ©es. Mettez en place des mÃ©canismes pour dÃ©tecter et corriger les discriminations.
    [Source](https://www.pmi.org/blog/top-10-ethical-considerations-for-ai-projects)

- **Garantir la transparence et lâ€™explicabilitÃ©**  
  Expliquez aux utilisateurs comment lâ€™IA arrive Ã  ses dÃ©cisions. IntÃ©grer des outils dâ€™Â«â€¯Explainable AIâ€¯Â» pour surmonter lâ€™effet de boÃ®te noire.
      [Source](https://www.pmi.org/blog/top-10-ethical-considerations-for-ai-projects)

- **Maintenir lâ€™humain dans la boucle**  
  PrivilÃ©giez le jugement humain, surtout pour les dÃ©cisions Ã  forts enjeux (santÃ©, justice, emploiâ€¦).
  [Source](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)
  

- **Assurer sÃ©curitÃ©, robustesse et durabilitÃ©**  
  ProtÃ©gez les systÃ¨mes contre les attaques et minimisez leur impact environnemental.

- **Ã‰tablir responsabilitÃ© et gouvernance**  
  Documentez et auditez les systÃ¨mes dâ€™IA, dÃ©finissez qui est responsable en cas de problÃ¨me.
    [Source](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)

- **Favoriser la collaboration et consultation**  
  Impliquez parties prenantes, experts et utilisateurs dÃ¨s la conception, adoptez une approche multidisciplinaire.
  [Source](https://en.wikipedia.org/wiki/Joy_Buolamwini)
  

- **Concevoir centrÃ© sur les valeurs humaines**  
  Utilisez des mÃ©thodes comme le *Value Sensitive Design* pour intÃ©grer les valeurs morales dÃ¨s le dÃ©part.
    [Source](https://en.wikipedia.org/wiki/Value_sensitive_design)

## ğŸš« Ã€ Ã©viter (Donâ€™ts)

- **Ne pas se reposer aveuglÃ©ment sur lâ€™IA**  
  Lâ€™automatisation complÃ¨te sans supervision humaine peut conduire Ã  des erreurs graves.
  [Source](https://www.instituteofaistudies.com/insights/ai-ethics-the-dos-and-donts-of-ai)

- **Ne pas ignorer les biais des donnÃ©es**  
  Se passer de contrÃ´le ou dâ€™audit introduit des biais non dÃ©tectÃ©s.

- **Ne pas violer la vie privÃ©e**  
  Ã‰vitez les collectes excessives sans raison ni consentement.

- **Ne pas sacrifier la sÃ©curitÃ©**  
  Compromettre la sÃ©curitÃ© pour lâ€™innovation expose Ã  des risques Ã©thiques et lÃ©gaux.

- **Ne pas se contenter dâ€™une gouvernance Ã  cocher**  
  Un cadre rigide ou trop bureaucratique empÃªche lâ€™innovation et ne sâ€™adapte pas.

- **Ne pas donner trop de pouvoir Ã  lâ€™IA**  
  Ne laissez jamais lâ€™IA prendre des dÃ©cisions affectant directement les droits ou la vie des personnes.

- **Ne pas nÃ©gliger lâ€™impact environnemental**  
  Les modÃ¨les IA gourmands en Ã©nergie doivent Ãªtre optimisÃ©s ou compensÃ©s.
    [Source](https://unsceb.org/sites/default/files/2022-09/Principles%20for%20the%20Ethical%20Use%20of%20AI%20in%20the%20UN%20System_1.pdf)

## ğŸ¨ En design (UX, design crÃ©atifâ€¦)

- **DÃ©clarer lâ€™usage de lâ€™IA**  
  Soyez transparent, mentionnez quand un visuel ou un texte est gÃ©nÃ©rÃ©.

- **Ne pas remplacer la recherche utilisateur**  
  Lâ€™IA ne doit pas se substituer aux mÃ©thodes qualitatives (entretiens, observations).

- **PrivilÃ©gier une IA comme assistant**  
  Lâ€™IA gÃ©nÃ¨re des propositions, le designer les critique, les filtre et les enrichit.

- **Cultiver la diversitÃ© et lâ€™inclusion**  
  IntÃ©grez des perspectives plurielles pour Ã©viter biais et stÃ©rÃ©otypes visuels.


## ğŸ“š Pour aller plus loin

- **UNESCO** : recommandations centrÃ©es sur les droits humains  
- **Toptal** : Ã©quitÃ©, transparence et responsabilitÃ© en design  